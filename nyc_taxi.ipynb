{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Import and Base Variable 확인\n",
    "#### 1) Data Import and DataFrame\n",
    "* 데이터 분석을 위해, dataframe을 생성하는 가장 일반적인 방법\n",
    "    * notebook 파일을 생성한 폴더에 분석하고자 하는 data파일을(e.g. csv) 옮겨둔다.\n",
    "    * data를 notebook으로 import.\n",
    "    * pandas 명령어로 data를 dataframe으로 생성.\n",
    "    * *tip : github는 push 할 수 있는 파일 1개 최대 용량이 100mb이므로 csv파일을 push할 경우 error발생  \n",
    "github에 csv은 push 못하므로, csv 파일은 add 하지말고 ipynb(주피터노트북파일 확장자) 파일만 add *\n",
    "***\n",
    "* 바로 dataframe을 만들지 않는 이유\n",
    "    * df을 여러 종류 만들 가능성(dfx,dfy 등)이 있기 때문에 이를 구분하기 위함  \n",
    "    * 또한 사용된 dataframe이 어떤 주제 및 소재인지를 표시\n",
    "     ***\n",
    "    * data를 dataframe으로 직접 생성  \n",
    "    df = pd.read_csv('train.csv')  \n",
    "    ***\n",
    "    * data와 dataframe을 각각 생성  \n",
    "    아래에서 사용되는 df은 taxi와 관련된 data로 만들어진 dataframe이다.  \n",
    "    *taxi를 dataframe의 name으로는 못 씀.   이미 data를 taxi로 정의함  \n",
    "    하나의 이름을 data로 쓰는 경우와 dataframe으로 쓰는 경우를 명확하게 구분하기 위함*  \n",
    "    taxi = 'train.csv'  \n",
    "    df = pd.read_csv(taxi)\n",
    "    ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi = 'train.csv' # data import\n",
    "df = pd.read_csv(taxi) # dataframe 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) DataFrame 살펴보기\n",
    " - shape           : row, column 개수 확인\n",
    " - head(), tail()  : 데이터 확인\n",
    " - describe()      : 각 column별 간략한 통계정보 \n",
    " - info()          : 각 column별 타입 정보"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) csv 데이터로 부터 DataFrame 생성\n",
    " * id : 식별자 for each trip\n",
    " * vendor_id : 공급자 코드(a code indicating the provider associated with the trip record)\n",
    " * pickup_datetime : 탑승 날짜 및 시각(date and time when the meter was engaged)\n",
    " * dropoff_datetime : 하차 날짜 및 시각(date and time when the meter was disengaged)\n",
    " * passengers in the vehicle : 승객수(driver entered value)\n",
    " * pickup_longitude : 탑승 경도(the longitude where the meter was engaged)\n",
    " * pickup_latitude : 탑승 위도(the latitude where the meter was engaged)\n",
    " * dropoff_longitude : 하차 경도(the longitude where the meter was disengaged)\n",
    " * dropoff_latitude : 하차 위도(the latitude where the meter was disengaged)\n",
    " * store_and_fwd_flag : 차량메모리 보관여부(this flage indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server. Y = store and forward, N = not a store and forward trip)\n",
    " * trip_duration : duration of the trip in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(701778, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # observation 및 column(변수) 갯수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id3495688</td>\n",
       "      <td>1</td>\n",
       "      <td>4/30/16 23:59</td>\n",
       "      <td>5/1/16 0:24</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.987793</td>\n",
       "      <td>40.724792</td>\n",
       "      <td>-73.975616</td>\n",
       "      <td>40.656445</td>\n",
       "      <td>N</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id3051282</td>\n",
       "      <td>1</td>\n",
       "      <td>4/30/16 23:59</td>\n",
       "      <td>5/1/16 0:22</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.957596</td>\n",
       "      <td>40.717770</td>\n",
       "      <td>-73.951424</td>\n",
       "      <td>40.775230</td>\n",
       "      <td>N</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id0082851</td>\n",
       "      <td>1</td>\n",
       "      <td>4/30/16 23:59</td>\n",
       "      <td>5/1/16 0:17</td>\n",
       "      <td>2</td>\n",
       "      <td>-74.000954</td>\n",
       "      <td>40.742031</td>\n",
       "      <td>-73.947708</td>\n",
       "      <td>40.782200</td>\n",
       "      <td>N</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id0515725</td>\n",
       "      <td>2</td>\n",
       "      <td>4/30/16 23:58</td>\n",
       "      <td>5/1/16 0:12</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.985733</td>\n",
       "      <td>40.738258</td>\n",
       "      <td>-73.993179</td>\n",
       "      <td>40.754890</td>\n",
       "      <td>N</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id1872374</td>\n",
       "      <td>2</td>\n",
       "      <td>4/30/16 23:58</td>\n",
       "      <td>5/1/16 0:17</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.006615</td>\n",
       "      <td>40.740650</td>\n",
       "      <td>-73.985619</td>\n",
       "      <td>40.723362</td>\n",
       "      <td>N</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id pickup_datetime dropoff_datetime  passenger_count  \\\n",
       "0  id3495688          1   4/30/16 23:59      5/1/16 0:24                1   \n",
       "1  id3051282          1   4/30/16 23:59      5/1/16 0:22                1   \n",
       "2  id0082851          1   4/30/16 23:59      5/1/16 0:17                2   \n",
       "3  id0515725          2   4/30/16 23:58      5/1/16 0:12                1   \n",
       "4  id1872374          2   4/30/16 23:58      5/1/16 0:17                1   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.987793        40.724792         -73.975616         40.656445   \n",
       "1        -73.957596        40.717770         -73.951424         40.775230   \n",
       "2        -74.000954        40.742031         -73.947708         40.782200   \n",
       "3        -73.985733        40.738258         -73.993179         40.754890   \n",
       "4        -74.006615        40.740650         -73.985619         40.723362   \n",
       "\n",
       "  store_and_fwd_flag  trip_duration  \n",
       "0                  N           1454  \n",
       "1                  N           1409  \n",
       "2                  N           1081  \n",
       "3                  N            800  \n",
       "4                  N           1151  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # data확인(head() 위 5개, tail() 아래 5개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>701778.000000</td>\n",
       "      <td>701778.000000</td>\n",
       "      <td>701778.000000</td>\n",
       "      <td>701778.000000</td>\n",
       "      <td>701778.000000</td>\n",
       "      <td>701778.000000</td>\n",
       "      <td>7.017780e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.536037</td>\n",
       "      <td>1.666577</td>\n",
       "      <td>-73.973665</td>\n",
       "      <td>40.750969</td>\n",
       "      <td>-73.973583</td>\n",
       "      <td>40.751836</td>\n",
       "      <td>9.387318e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498700</td>\n",
       "      <td>1.319466</td>\n",
       "      <td>0.043910</td>\n",
       "      <td>0.033139</td>\n",
       "      <td>0.044214</td>\n",
       "      <td>0.037572</td>\n",
       "      <td>6.772504e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-78.547401</td>\n",
       "      <td>34.359695</td>\n",
       "      <td>-79.817978</td>\n",
       "      <td>32.181141</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.991829</td>\n",
       "      <td>40.737400</td>\n",
       "      <td>-73.991325</td>\n",
       "      <td>40.735959</td>\n",
       "      <td>3.900000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.981789</td>\n",
       "      <td>40.754150</td>\n",
       "      <td>-73.979828</td>\n",
       "      <td>40.754478</td>\n",
       "      <td>6.480000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-73.967567</td>\n",
       "      <td>40.768246</td>\n",
       "      <td>-73.963249</td>\n",
       "      <td>40.769691</td>\n",
       "      <td>1.047000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-61.335529</td>\n",
       "      <td>43.486885</td>\n",
       "      <td>-61.335529</td>\n",
       "      <td>43.674000</td>\n",
       "      <td>3.526282e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           vendor_id  passenger_count  pickup_longitude  pickup_latitude  \\\n",
       "count  701778.000000    701778.000000     701778.000000    701778.000000   \n",
       "mean        1.536037         1.666577        -73.973665        40.750969   \n",
       "std         0.498700         1.319466          0.043910         0.033139   \n",
       "min         1.000000         0.000000        -78.547401        34.359695   \n",
       "25%         1.000000         1.000000        -73.991829        40.737400   \n",
       "50%         2.000000         1.000000        -73.981789        40.754150   \n",
       "75%         2.000000         2.000000        -73.967567        40.768246   \n",
       "max         2.000000         8.000000        -61.335529        43.486885   \n",
       "\n",
       "       dropoff_longitude  dropoff_latitude  trip_duration  \n",
       "count      701778.000000     701778.000000   7.017780e+05  \n",
       "mean          -73.973583         40.751836   9.387318e+02  \n",
       "std             0.044214          0.037572   6.772504e+03  \n",
       "min           -79.817978         32.181141   1.000000e+00  \n",
       "25%           -73.991325         40.735959   3.900000e+02  \n",
       "50%           -73.979828         40.754478   6.480000e+02  \n",
       "75%           -73.963249         40.769691   1.047000e+03  \n",
       "max           -61.335529         43.674000   3.526282e+06  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() # 변수별 기초통계량 확인(mean과 50%비교, real변수와 category변수 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 701778 entries, 0 to 701777\n",
      "Data columns (total 11 columns):\n",
      "id                    701778 non-null object\n",
      "vendor_id             701778 non-null int64\n",
      "pickup_datetime       701778 non-null object\n",
      "dropoff_datetime      701778 non-null object\n",
      "passenger_count       701778 non-null int64\n",
      "pickup_longitude      701778 non-null float64\n",
      "pickup_latitude       701778 non-null float64\n",
      "dropoff_longitude     701778 non-null float64\n",
      "dropoff_latitude      701778 non-null float64\n",
      "store_and_fwd_flag    701778 non-null object\n",
      "trip_duration         701778 non-null int64\n",
      "dtypes: float64(4), int64(3), object(4)\n",
      "memory usage: 58.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # Variable Type 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Pre-Processing\n",
    "#### 1) Datatime Type Vriable Modify \n",
    "\n",
    "* **Datetime Type Conversion**\n",
    "    * pickup_datetime, dropoff_datetime은 type이 datetime이어야 시간변수로 활용할 수  \n",
    "    있으나, object(=string)임\n",
    "    * 시간변수로 활용하기 위해 type을 datetime으로 바꿔줘야 함\n",
    "    * pandas의 to_datetime을 활용해 type을 datetime으로 바꿔줄 수 있음\n",
    "    * datafrme의 변수타입을 변경하는 코드는 다음과 같음\n",
    "        * 방법 1  \n",
    "        taxi_df.pickup_datetime = pd.to_datetime(taxi_df.pickup_datetime)  \n",
    "        * 방법 2  \n",
    "        taxi_df['pickup_datetime'] = pd.to_datetime(taxi_df['pickup_datetime']) \n",
    "    * dataframe에서 새로운 변수를 생성할 경우 등호(=)의 오른쪽은 df.변수명, df['변수명']  \n",
    "    둘다 상관 없으나, 새로운 변수명(왼쪽)은 df['변수명']으로 적어야 생성됨  \n",
    "    새로운 변수명(왼쪽)을 df.변수명으로 적을 경우 kernel이 작동하지만 실제로 생성은 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pickup_datetime.dtype # 시간변수 type 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70178, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컴퓨터가 느릴 경우 여기서 샘플링\n",
    "df = df.sample(frac = 0.1, replace = False, random_state = 0) # sampling\n",
    "df.shape # sampling됐는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간변수 type을 datetime type으로 변환(pandas datetimeIndex 이용)\n",
    "df.pickup_datetime = pd.to_datetime(df.pickup_datetime)\n",
    "df.dropoff_datetime = pd.to_datetime(df.dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 참고 skip\n",
    "# pickup - dropoff의 계산을 통해 trip_duration 검증 및 pickup, dropoff, trip_duration 변수 관계 확인\n",
    "#df.trip_duration_c = df.dropoff_datetime - df.pickup_datetime\n",
    "\n",
    "# trip_duration_c는 day단위로 산출됨.\n",
    "#df.trip_duration_c = df.trip_duration_c.dt.total_seconds() # second로 단위 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-11-bd9a612b30b5>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-bd9a612b30b5>\"\u001b[1;36m, line \u001b[1;32m23\u001b[0m\n\u001b[1;33m    df.head()\u001b[0m\n\u001b[1;37m             \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# pickup_datetime을 각 항목별로 slicing (slicing은 str밖에 안되므로 타입을 str로바꿔서 slicing)\n",
    "df['pickup_datetime'] = df.pickup_datetime.astype(str)\n",
    "df['pickup_year'] = df.pickup_datetime.str[:4]\n",
    "\n",
    "# pickup_year의 type을 string에서 int로 다시 바꿔줌\n",
    "df['pickup_year'] = df.pickup_year.astype(int)\n",
    "\n",
    "# 위의 방법을 month, day, hour, mm에 반복  (보다 효율적으로 하는 방법(loop등)이 있을 것 같음)\n",
    "df['pickup_month'] = df.pickup_datetime.str[5:7]\n",
    "df['pickup_month'] = df.pickup_month.astype(int)\n",
    "df['pickup_day'] = df.pickup_datetime.str[8:10]\n",
    "df['pickup_day'] = df.pickup_day.astype(int)\n",
    "df['pickup_hour'] = df.pickup_datetime.str[10:13]\n",
    "df['pickup_hour'] = df.pickup_hour.astype(int)\n",
    "df['pickup_mm'] = df.pickup_datetime.str[14:16]\n",
    "df['pickup_mm'] = df.pickup_mm.astype(int)\n",
    "\n",
    "# 생성된 변수 타입 확인\n",
    "df.info()\n",
    "\n",
    "# 생성된 변수 dataframe 적용 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Use the Pandas.Datetimeindex module\n",
    "* dataframe_name.datetime_variable_name.dt.**option**  \n",
    "**option**(year, month, day, hour, dayofyear, dayofweek 등)은 [참고링크](https://pandas.pydata.org/pandas-docs/stable/api.html#datetimeindex)에서 확인\n",
    "---\n",
    "* 특정 변수 생성(datetime variable에서 연, 월, 일 각각 변수로 분리)  \n",
    "일 변수 : taxi_df['pickup_day'] = taxi_df.pickup_datetime.dt.day  \n",
    "* 단위 변환한 변수 생성(week 기준 몇번째 일이냐, 요일 변수 생성)  \n",
    "요일변수 : taxi_df['wday'] = taxi_df.pickup_datetime.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 탄 시간, 일, 월, 연도를 카테고리 타입의 변수로 생성\n",
    "df['pickup_hour'] = df.pickup_datetime.dt.hour.astype('category')\n",
    "df['pickup_day'] = df.pickup_datetime.dt.day.astype('category')\n",
    "df['pickup_month'] = df.pickup_datetime.dt.month.astype('category')\n",
    "df['pickup_year'] = df.pickup_datetime.dt.year.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 연도, 주 기준 변수 생성\n",
    "df['yday'] = df.pickup_datetime.dt.dayofyear.astype('category')\n",
    "df['wday'] = df.pickup_datetime.dt.dayofweek.astype('category')\n",
    "df['nwday'] = df.pickup_datetime.dt.weekday_name.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.vendor_id = df.vendor_id.astype('category') # vendor type category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) data log 변환\n",
    "* trip_duration의 단위는 second로 log변환 가능\n",
    "* trip_duration에 +1(scaling)을 한 후 log 변환 수행  \n",
    "*original 값에 +1을 하는 이유 :\n",
    "original 값이 0인 경우 log변환하면 1이 되어버림 따라서, 모든 original 값에 1을 더함*\n",
    "* tirp_duraiont+1을 log변환 함\n",
    "* original 값과 log변환 값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['logtrip_duration'] = np.log(df.trip_duration + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tip : 기존 dataframe에 변수를 추가했을 때 활용할 수 있는 명령어(변수명 변경, 변수 삭제, 변수 순서 변경)\n",
    "* 변수명(column) 변경(rename)\n",
    "    * 방법1 : df = df.rename(columns = {'oldname1' : 'newname1', 'oldname2' : 'newname2'})\n",
    "    * 방법2 : df.rename(columns = {'oldname1' : 'newname1', 'oldname2' : 'newname2'}, inplace = True)\n",
    "* 잘못 생성한 변수(column) 삭제(drop)\n",
    "    * 방법1 : df = df.drop('column_name', axis = 1)  \n",
    "    *axis = 1은 dataframe의 column을 의미(0은 row)*\n",
    "    * 방법2 : df.drop('column_name', axis = 1, inplace = True)\n",
    "* 변수(column) 순서 변경(order or insert)\n",
    "    * 방법1 : df = df.[['column1', 'column2']]\n",
    "    * 방법2 : 특정자리에 특정 변수 삽입\n",
    "        * get a list of columns   \n",
    "        cols = list(df)\n",
    "        * move the column to head of list using index, pop and insert  \n",
    "        cols.insert(0, cols.pop(cols.index('column_name')))\n",
    "        * use loc to reorder(라벨을 활용할 경우 loc, 위치 index를 활용할 경우 iloc)  \n",
    "        df = df.loc[:, cols]                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 변수 순서 조정\n",
    "cols = list(df) # dataframe을 list로 type변환 -> 변수명만 포함한 리스트(cols) 생성\n",
    "cols.insert(0, cols.pop(cols.index('trip_duration'))) # 종속변수를 잘라내어(pop) cols맨 앞(index 0)에 삽입(insert)\n",
    "cols.insert(1, cols.pop(cols.index('logtrip_duration')))\n",
    "cols.insert(2, cols.pop(cols.index('vendor_id'))) # 독립변수1를 잘라내어(pop) index 2에 삽입(insert)\n",
    "cols.insert(3, cols.pop(cols.index('pickup_month')))\n",
    "cols.insert(4, cols.pop(cols.index('wday')))\n",
    "cols.insert(5, cols.pop(cols.index('pickup_day')))\n",
    "cols.insert(6, cols.pop(cols.index('passenger_count')))\n",
    "df = df.loc[:, cols] # 행은 그대로, 열은 cols(변수명 리스트)로 다시 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sampling  \n",
    "분석하거나 그래프 그릴 때 모든 데이터를 사용할 경우 수행시간이 너무 길어짐  \n",
    "이에 sample 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_group = df.groupby('pickup_month') # original data 확인을 위해 grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "month_group.count() # pickup_month의 variable*column별 관측치 수 확인\n",
    "\n",
    "# size함수를 통해 pickup_month의 value별 관측치 수 확인(count와 size의 차이 : size는 NaN값을 포함해서 세고, count는 NaN값을 세지 않음)\n",
    "# month_group.size().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 했으므로 여기서는 실행 안함. 원래 여기서 시행해야 아래 표와 차이 발생\n",
    "# df = df.sample(frac = 0.1, replace = False, random_state = 0) # sampling\n",
    "# df.shape # sampling됐는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample이 골고루 뽑혔는지 확인\n",
    "# month_group.count()의 output과 비교. 월별 갯수 비중 확인\n",
    "\n",
    "# pickup_month data 확인을 위해 grouping\n",
    "month_group = df.groupby('pickup_month')\n",
    "# pickup_month의 variable*column별 관측치 수 확인\n",
    "month_group.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (4) Base Data Graph\n",
    "* RawData가 너무 많을 경우 Sampling\n",
    "* Graph 그리는 Package Import\n",
    "    1. Matplotlib  \n",
    "        * 간단한 시각화를 하는 경우 pylab subpackage만으로 충분함  \n",
    "    import matplotlib as mpl  \n",
    "    import matplotlib.pylab as plt  \n",
    "    1. Seaborn  \n",
    "        * Matplotlib을 기반으로 기능을 추가한 시각화 패키지로 Matplotlib에 의존  \n",
    "    *Seaborn을 import하면 Matplotlib에서 제공하는 기본 스타일이 아닌 Seaborn에서 지정한 Default 스타일 집합으로 변경함  \n",
    "    따라서 동일한 Matplotlib명령을 수행해도 Seaborn을 import한 것과 하지 않은 플롯은 모양이 다름*  \n",
    "    import seaborn as sns  \n",
    "    sns.set()  \n",
    "    sns.set_color_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_color_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# trip_duration과 logtrip_duration의 kernel density graph\n",
    "# 아래의 sns는 너무 오래걸림\n",
    "sns.distplot(df.trip_duration, kde = True, rug = True)\n",
    "plt.show()\n",
    "sns.distplot(df.logtrip_duration, kde = True, rug = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* boxplot 보는 방법\n",
    "<img src=\"boxplot-1.png\">\n",
    "* 그래프 저장 방법  \n",
    "from pylab import figure, axes, pie, title, savefig #savefig추가  \n",
    "savefig('boxplot.png') # graph 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(\"trip_duration\", \"pickup_month\") # 데이터의 분포를 확인할 때 boxplot 사용\n",
    "plt.ylim(-10, 2500)\n",
    "plt.xlim(0, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(\"logtrip_duration\", \"pickup_month\") # log변환 했을 때 더 정규분포에 가까워지는 것을 확인할 수 있음\n",
    "plt.ylim(4, 10)\n",
    "plt.xlim(0, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df.trip_duration) # kernel density grahp (높이(x가 뽑힐 확률)는 큰 의미 없음, 넓이가 중요(넓이의 합은 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(df.logtrip_duration) # 정규분포와 더 유사한 분포가 됨\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (5) Outlier 확인 및 삭제\n",
    "* 눈으로 확인하는 방법\n",
    "    * outlier 삭제(1750000초 이상인 경우 빈도가 매우 적고 숫자가 너무 커 outlier로 판단) \n",
    "    * *trip_duration이 20,000초 이상(5시간 이상)인 경우는 일반적인 상황이 아닌 것(분석 data에서 제외)으로 고려하고 분석할 수 있을 것으로 판단*  \n",
    "    ***\n",
    "* OLS를 통해 확인하는 방법\n",
    "    * ols를 통해 레버리지와 잔차를 계산하여 이를 근거로 outlier 규정\n",
    "***\n",
    "* Outlier 삭제\n",
    "    * 특정 관측치 삭제  \n",
    "    df = df.drop([index])\n",
    "    df = df.drop()(axis=0)  \n",
    "\n",
    "    * 특정 범위만 grab  \n",
    "    df = df[df.변수명 <= 1750000]  \n",
    "    df[(df.변수명 >= 1750000) & (df.변수명 <= 2000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.wday, df.trip_duration)\n",
    "plt.xlabel(\"day of week\")\n",
    "plt.ylabel(\"trip_duration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치라 판단되는 data확인\n",
    "df[df.trip_duration >= 1750000]\n",
    "\n",
    "# 아래의 형식으로도 확인 가능\n",
    "# df[(df.trip_duration >= 1750000) & (df.trip_duration <= 2000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 관측치 삭제\n",
    "#df = df.drop([682482])\n",
    "#df = df.drop()(axis=0)\n",
    "\n",
    "# 특정 범위만 grab\n",
    "df = df[df.trip_duration <= 1750000]\n",
    "#df[(df.trip_duration >= 1750000) & (df.trip_duration <= 2000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 삭제되었는지 확인\n",
    "plt.scatter(df.pickup_month, df.trip_duration)\n",
    "plt.xlabel(\"pickup_month\")\n",
    "plt.ylabel(\"trip_duration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = cols[2:7] # feature list\n",
    "y = cols[1:2] # target list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = y + x\n",
    "sns.pairplot(df[variable])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "df[(np.abs(stats.zscore(df)) < 3).all(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* time-series data outlier 확인  \n",
    "[참고사이트](https://ocefpaf.github.io/python4oceanographers/blog/2015/03/16/outlier_detection/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (참고) datetime variable 조정\n",
    "* pandas의 datetimeIndex로 datetime변수를 만들면 보통 시간(초(second) 단위)까지 생성됨\n",
    "* datetime변수가 날짜만 필요할 때 활용\n",
    "    1. old_datetime variable을 str type으로 변경\n",
    "    1. 필요한 단위까지 slicing해서 new_datetime 변수 생성\n",
    "    1. datetime type으로 변경\n",
    "***\n",
    "* time-series graph 그릴때 datetime 변수를 index로 설정\n",
    "\n",
    "    * datetime 변수를 index로 설정  \n",
    "df = df.set_index('datetime_variable')\n",
    "\n",
    "    * index 초기화(index로 사용되던 변수를 column으로 보내고, 다시 본래 index)  \n",
    "df = df.reset_index() # index reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# pickuptime variable을 일까지의 단위로 조정\n",
    "\n",
    "df.pickup_datetime = df.pickup_datetime.astype(str)\n",
    "df['pickup_datetime1'] = df.pickup_datetime.str[:7] # 시간까지만 pickup_datetime\n",
    "df.pickup_datetime1 = pd.to_datetime(df.pickup_datetime1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.set_index('pickup_datetime1') # pickup_datetime1을 index로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.reset_index() # index reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median_filtered(signal, threshold=3):\n",
    "    signal = signal.copy()\n",
    "    difference = np.abs(signal - np.median(signal))\n",
    "    median_difference = np.median(difference)\n",
    "    if median_difference == 0:\n",
    "        s = 0\n",
    "    else:\n",
    "        s = difference / float(median_difference)\n",
    "    mask = s > threshold\n",
    "    signal[mask] = np.median(signal)\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figsize = (7, 2.75)\n",
    "kw = dict(marker='o', linestyle='none', color='r', alpha=0.3)\n",
    "\n",
    "df['trip_duration_medf'] = get_median_filtered(df.trip_duration.values, threshold=3)\n",
    "\n",
    "outlier_idx = np.where(df['trip_duration_medf'].values != df.trip_duration.values)[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "df.trip_duration.plot()\n",
    "df.trip_duration[outlier_idx].plot(**kw)\n",
    "_ = ax.set_ylim(0, 100000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.plt.scatter('pickup_datetime1', 'trip_duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.pickup_datetime1, df.trip_duration)\n",
    "plt.xlabel(\"pickup\")\n",
    "plt.ylabel(\"trip_duration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* OLS를 통한 outlier 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX0 = pd.DataFrame(df, columns = x) # feature dataframe 생성\n",
    "# add_constant는 y절편을 의미(모형에서 상수값), 이를 생성하지 않을경우 y절편이 0으로 고정되어 모형이 왜곡됨\n",
    "dfX = sm.add_constant(dfX0) # 값을 1로 갖는 column vector를 생성하여 X dataframe에 추가\n",
    "dfy = pd.DataFrame(df, columns = y) # feature dataframe 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.vendor_id, df.trip_duration)\n",
    "plt.xlabel(\"vendor\")\n",
    "plt.ylabel(\"trip_duration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = sm.OLS.from_formula(\"trip_duration ~ C(vendor_id) + 0\", df)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The rsquared values is \" + str(result.rsquared))\n",
    "plt.scatter(df.vendor_id, df.trip_duration)\n",
    "plt.show()\n",
    "plt.scatter(np.mean(x1), np.mean(y1), color = \"green\")\n",
    "plt.plot(np.sort(x1), y0[np.argsort(x1)], label = \"actual\")\n",
    "plt.plot(np.sort(x1), lm.predict()[np.argsort(x1)], label = \"regression\")\n",
    "plt.title(\"Linear Regression plots with the regression line\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The rsquared values is \" + str(result.rsquared))\n",
    "plt.scatter(df.wday, df.trip_duration)\n",
    "plt.scatter(np.mean(x1), np.mean(y1), color = \"green\")\n",
    "plt.plot(np.sort(x1), y0[np.argsort(x1)], label = \"actual\")\n",
    "plt.plot(np.sort(x1), lm.predict()[np.argsort(x1)], label = \"regression\")\n",
    "plt.title(\"Linear Regression plots with the regression line\")\n",
    "plt.legend()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "fig = sm.graphics.influence_plot(lm, alpha  = 0.05, ax = ax, criterion=\"cooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = result.get_influence()\n",
    "hat = influence.hat_matrix_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hat.sum() =\", hat.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.plot_leverage_resid2(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_taxi = smf.OLS(dfy, dfX)\n",
    "result_taxi = model_taxi.fit()\n",
    "print(result_taxi.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = result.get_influence()\n",
    "hat = influence.hat_matrix_diag\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.stem(hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm.graphics.plot_leverage_resid2(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickup_month data histogram\n",
    "plt.hist(taxi_df.wday)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(taxi_df.pickup_month)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(x, bins=None, range=None, normed=False, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, hold=None, data=None, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "influence = result.get_influence()\n",
    "hat = influence.hat_matrix_diag\n",
    "\n",
    "plt.figure(figsize = (10, 2))\n",
    "plt.stem(hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figersize=(10, 2))\n",
    "plt.stem(result.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.rugplot(taxi_df.trip_duration)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(taxi_df.trip_duration)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(taxi_df.trip_duration, kde = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdf = taxi_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdf = taxi_df.copy()\n",
    "trip_duration = newdf.groupby('trip_duration')\n",
    "newdf[np.abs(newdf.trip_duration - newdf.trip_duration.mean()) <= (3 * newdf.trip_duration.std())]\n",
    "newdf['outlier'] = trip_duration.transform(lambda x: abs(x - x.mean()) > 1.96 * x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(taxi_df.vendor_id, taxi_df.trip_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vendor_id와 trip_duration간 scatter graph \n",
    "plt.scatter(len(taxi_df.vendor_id), taxi_df.trip_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(taxi_df.vendor_id, taxi_df.trip_duration)\n",
    "plt.ylim(1930000, 1950000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(taxi_df.vendor_id, taxi_df.trip_duration)\n",
    "plt.ylim(0, 150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(taxi_df.pickup_latitude, taxi_df.pickup_longitude, s = taxi_df.trip_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['agg.path.chunksize'] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Create Weather Variable\n",
    "##### (1) Create Quarterly Category Variable\n",
    "* pickup_month가 1월 ~ 4월까지 밖에 없음(kaggledata는 6월까지)\n",
    "* 1, 2, 3월은 겨울의 계절성을 반영하고, 4, 5, 6월은 봄 ~ 초여름의 계절성을 반영한다고 가정함.\n",
    "    * 사람들이 기후조건이 가혹할수록 더 택시를 오래 타고 있는다고 가정(날이 추우면 최대한 목적지에 가까운 장소까지 택시를 타고 간다.)\n",
    "    * 이 가정을 반영하기 위해서는 뉴욕의 날씨를 확인해서 비오는 날과 맑은 날, 날짜별 온도를 변수화해서 반영하는 것이 보다 정확할 것으로 생각함 \n",
    "        * 변수 2개 생성(날짜별로 비 or 눈이 왔다 0 나머지 1, 기온이 00도 이상 or 00도 이하 0, 나머지 1)해서 pickup_datetime으로 merge.\n",
    "    * 가장 rough하게 변수를 생성해서 모형을 실행한 다음 이 변수가 유의미할 경우 더 세밀하게 변수를 조정하는 것이 나을 듯함\n",
    "    \n",
    "    \n",
    "* 계절성을 반영한 분기별 카테고리 변수(pickup_month_c) 생성 1, 2, 3월은 0, 4, 5, 6월은 1의 값을 가짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickup_month data 확인을 위해 grouping\n",
    "month_group = taxi_df.groupby('pickup_month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickup_month의 value*column별 관측치 수 확인\n",
    "month_group.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# size함수를 통해 pickup_month의 value별 관측치 수 확인(count와 size의 차이 : size는 NaN값을 포함해서 세고, count는 NaN값을 세지 않음)\n",
    "month_group.size().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# category variable 만듦(1, 2, 3월은 0, 4, 5, 6월은 1) (더미변수를 따로 만드는 것과 같은 효과라 판단함)\n",
    "taxi_df['pickup_month_c'] = taxi_df.pickup_month.replace([1, 2, 3], '0')\n",
    "taxi_df['pickup_month_c'] = taxi_df.pickup_month_c.replace([4], '1')\n",
    "\n",
    "# type 변경(to category) 및 type 확인\n",
    "taxi_df.pickup_month_c = taxi_df.pickup_month_c.astype('category')\n",
    "taxi_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Create wdf data\n",
    "* 2016년 뉴욕 날씨 데이터를 입력하여 yday를 기준변수로 활용하여 기존 data frame에 merge함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2016년 뉴욕 날씨 데이터 입력\n",
    "wdf = pd.read_csv('weather_data_nyc_centralpark_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wdf['date'] = pd.to_datetime(wdf.date,format='%d-%m-%Y')\n",
    "wdf['yday'] = wdf.date.dt.dayofyear\n",
    "# wdf['wday'] = wdf.date.dt.dayofweek\n",
    "# wday변수는 wdf에서 안만들어도 될 것 같아서 만들지 않음\n",
    "# merge하는데 필요한 기준 변수는 1개면 충분하다고 판단함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data확인결과 pricipitation 등의 변수에 숫자가 아닌 T가 있음\n",
    "wdf.head(10)\n",
    "# T는 측정되지 않았으나 비가왔던 흔적을 의미함\n",
    "#\"T\" stands for \"trace\", used when precipitation has been detected, but it isn't sufficient to measure meaningfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# T를 아주 작은 수로 바꿔줌(여기서는 0.01로 변경)\n",
    "falls = [ 0.01 if c=='T' else float(c) for c in wdf['snow fall']]\n",
    "rain = [ 0.01 if c=='T' else float(c) for c in wdf['precipitation']]\n",
    "wdf['snow fall']= falls\n",
    "wdf['precipitation'] = rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'yday' 변수를 기준변수로 taxi_df에 wdf를 merge함\n",
    "# (yday를 기준으로 taxi_df에 wdf의 data를 가로로 붙인다.)\n",
    "taxi_df = pd.merge(taxi_df,wdf,on='yday')\n",
    "taxi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 필요없는 변수 삭제(maximum과 minimum은 같은 지역으로 다 같기 때문에 삭제)\n",
    "taxi_df = taxi_df.drop(['date','maximum temperature','minimum temperature'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* (temp) 독립변수(ex.pickup_month_c)와 종속변수(ex.trip_duration)의 상관관계 확인\n",
    "* 상관계수 해석\n",
    "    * +값은 비례, -값은 반비례를 의미\n",
    "    * 상관계수의 크기에 따른 해석은 관행적으로 이뤄지는 것으로, 이론적 근거는 없음\n",
    "        * 1.0 ~ 0.7 매우 강한 관련성\n",
    "        * 0.7 ~ 0.4 상당한 관련성\n",
    "        * 0.4 ~ 0.2 약간의 관련성\n",
    "        * 0.2 ~ 0.0 관련성 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 설명변수 type이 int나 float와 같은 real변수일 경우\n",
    "taxi_df[['trip_duration','pickup_month']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# category변수일 경우(p-value를 소수점 2자리로 나오게 하는 방법 필요할 듯)\n",
    "from scipy.stats import spearmanr, kendalltau, pearsonr\n",
    "spearmanr(taxi_df['trip_duration'], taxi_df['pickup_month_c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 참고 : Pandas의 DatetimeIndex와 Python의 Datetime Package는 다름\n",
    "\n",
    "> Python의 Datetime을 활용해 단위를 변경하는 명령어는 week와 관련된 명령어(weekday(), isoweekday()) 밖에 없음  \n",
    "year와 month등을 기준(ex.1년 365일 중 4월 30일이 몇 번째 날)으로 datatime type 변수의 단위를 변경하기 위해서는 timetuple이나 strftime를 적용하여 사용하는 방법이 따로 적혀있음.   \n",
    "그런데 dt.dayofyear, dayofweek, dayofmonth 등의 명령어가 실행이 됨.\n",
    "[google 검색 결과](https://stackoverflow.com/questions/15707532/python-import-datetime-v-s-from-datetime-import-datetime)에서 import datetime as dt한 것을 보고 dt를 python의 datetime package로 오해함.  \n",
    "그러나 참고한 자료에서는 import datetime 자체를 하지 않음.  \n",
    "dt는 python의 datetime를 의미할 수도 있지만 여기서는 아닌 pandas의 **DatetimeIndex**를 의미함  \n",
    "\n",
    "####### (2) Use the Datetime Package\n",
    "* **Datatime Package를 이용해 연, 월, 일 변수 생성  **\n",
    "    * datatime package 설치 : import datetime\n",
    "    * df['option 기준 변수명'] = df['datetime_type_variable_name'].datetime.option  \n",
    "        * option(year, month, day, houre, minut, second 등)\n",
    "            * dataframe_name['시간 기준 변수명'] = dataframe_name['기존변수명'].datetime.hour  \n",
    "            * dataframe_name['연 기준 변수명'] = dataframe_name['기존변수명'].datetime.year\n",
    "        * option에 따라 변수값의 기준이 달라짐  \n",
    "    MINYEAR <= year <= MAXYEAR,  \n",
    "    1 <= month <= 12,  \n",
    "    1 <= day <= number of days in the given month and year,  \n",
    "    0 <= hour < 24,  \n",
    "    0 <= minute < 60,  \n",
    "    0 <= second < 60,  \n",
    "    0 <= microsecond < 1000000,  \n",
    "    fold in [0, 1].  \n",
    "---\n",
    "* **Datetime Package의 timetuple 또는 strftime module을 활용한 단위 변경  **\n",
    "> *패키지(Packages)는 도트(.)를 이용하여 파이썬 모듈을 계층적(디렉터리 구조)으로 관리할 수 있게 해준다. 예를 들어 모듈명이 A.B인 경우 A는 패키지명이 되고 B는 A 패키지의 B 모듈이 된다.  *\n",
    "\n",
    "\n",
    "\n",
    "    * datetime package만을 활용한 단위 변경\n",
    "        * week 기준 day 산출(7일 중 몇 번째 일(요일을 알 수 있음))  \n",
    "            * df['week 단위 변수명'] = df['기존변수명'].dt.weekday   \n",
    "            df['week 단위 변수명'] = df['기존변수명'].dt.isoweekday  \n",
    "            df['week 단위 변수명'] = df['기존변수명'].dt.weekday_name \n",
    "> weekday : monday == 0 ... sunday == 6  \n",
    "            isoweekday : monday == 1 ... sunday == 7   \n",
    "            weekday_name : monday == monday ... sunday == sunday  \n",
    "        * year 기준 day 산출(해당년 첫번째날(1월 1일) == 1을 기준으로 1년 중 몇 번째 일인지 알 수 있음)  \n",
    "       > df['year 단위 변수명'] = df['기존변수명'].dt.dayofyear   \n",
    " \n",
    "        * month 기준 day 산출(해당월 첫번째 날 == 1을 기준으로 해당 월 중 몇 번째 일인지 알 수 있음)  \n",
    "       > df['month 단위 변수명'] = df['기존변수명'].dt.dayofmonth  \n",
    "        * dayofweek도 실행됨\n",
    "---\n",
    "* 참고\n",
    "    * timetuple 활용\n",
    "        * df['new_variable'] = df['datetime_variable'].dt.timetuple(option)\n",
    "        * option : d.year, d.month, d.day, d.hour, d.minute, d.second, d.weekday(), yday, dst  \n",
    "    MINYEAR <= year <= MAXYEAR  \n",
    "    1 <= month <= 12  \n",
    "    1 <= day <= number of days in the given month and year \n",
    "    * strftime 활용\n",
    "        * df['new_variable'] = df['datetime_variable'].dt.strftime('%j')  \n",
    "        %j는 c언어로 day of the year as a zero-padded decimal number를 의미함  \n",
    "        pandas datetimeindex의 dayofyear와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "taxi_df['temp'] = taxi_df['pickup_datetime'].dt.strftime('%j')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 2) 공간변수(or 지도정보, 위치정보) 사용 \n",
    "  * 지도정보(위치정보)를 활용하기 위해서는 folium(포리움)함수를 사용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the airports data.\n",
    "pickup = pd.read_csv(\"train.csv\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Get a basic world map.\n",
    "taxi_map = folium.Map(location=[30, 0], zoom_start=2)\n",
    "# Draw markers on the map.\n",
    "for name, row in airports.iterrows():\n",
    "    # For some reason, this one airport causes issues with the map.\n",
    "    if row[\"vendor_id\"] != \"South Pole Station\":\n",
    "        taxi_map.circle_marker(location=[row[\"latitude\"], row[\"longitude\"]], popup=row[\"name\"])\n",
    "# Create and show the map.\n",
    "airports_map.create_map('airports.html')\n",
    "airports_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the airlines data.\n",
    "pickup = pd.read_csv(\"airlines.csv\", header=None, dtype=str)\n",
    "airlines.columns = [\"id\", \"name\", \"alias\", \"iata\", \"icao\", \"callsign\", \"country\", \"active\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the airports data.\n",
    "pickup = pandas.read_csv(\"train.csv\", dtype=str)\n",
    "\n",
    "# Read in the airlines data.\n",
    "airlines = pandas.read_csv(\"airlines.csv\", header=None, dtype=str)\n",
    "airlines.columns = [\"id\", \"name\", \"alias\", \"iata\", \"icao\", \"callsign\", \"country\", \"active\"]\n",
    "# Read in the routes data.\n",
    "routes = pandas.read_csv(\"routes.csv\", header=None, dtype=str)\n",
    "routes.columns = [\"airline\", \"airline_id\", \"source\", \"source_id\", \"dest\", \"dest_id\", \"codeshare\", \"stops\", \"equipment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_df = pd.DataFrame(columns = ['pickup_latitude','pickup_longitude'])\n",
    "\n",
    "ctr = 0\n",
    "for place in query_result.places:\n",
    "    for key, item in place.geo_location.items():\n",
    "        df.loc[ctr, key] = item\n",
    "    ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi_df['pickup_locations'] = taxi_df['pickup_latitude', 'pickup_longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#correlation 확인\n",
    "taxi_df['trip_duration'].corr(taxi_df['pickup_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taxi_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi_df['pickup_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickup_date_group = taxi_df.groupby(lambda pickup_datetime : pickup_datetime.split(' ')[0])\n",
    "pickup_date_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfy = taxi_df.ix[:,10:11]\n",
    "dfX = taxi_df.ix[:,:10]\n",
    "print(len(dfy.columns), len(dfX.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfX.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_real = ['pickup_datetime', 'dropoff_datetime', 'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_cat = ['id', 'vendor_id', 'store_and_fwd_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfX_real = dfX[cols_real]\n",
    "print(len(dfX_real.columns))\n",
    "dfX_real.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfX_cat = dfX[cols_cat]\n",
    "print(len(dfX_cat.columns))\n",
    "dfX_cat.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(cols_real), 4):\n",
    "    print(\"dfX{}\".format(cols_real[i: i+4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"pickup_datetime\", y=\"trip_duration\", data=taxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
